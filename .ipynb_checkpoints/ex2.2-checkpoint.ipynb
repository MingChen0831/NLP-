{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887741eb",
   "metadata": {},
   "source": [
    "### 第2题 word2vec向量表示和文本分类（30分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be19e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import word2vec    #w2v包\n",
    "import numpy as np\n",
    "\n",
    "#review corpus: [reveiws,y]\n",
    "y=[]\n",
    "reviews=[]\n",
    "with open(\"train.txt\",'r',encoding='utf-8') as infile: # train.txt=>sentence list\n",
    "    for line in infile:\n",
    "        label, sentence = line.strip().split(\"\\t\")\n",
    "        y.append(int(label))\n",
    "        reviews.append(sentence)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(reviews, y,test_size=0.2)\n",
    "\n",
    "\n",
    "#sentence ->word list\n",
    "def cleanText(corpus):  #输入corpus: sentence list\n",
    "    corpus=[z.lower().replace('\\n','').split() for z in corpus]\n",
    "    # corpus=[z.replace('.','').split() for z in corpus]\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "x_train=cleanText(x_train)   # =>lowercase, word list\n",
    "x_test=cleanText(x_test)\n",
    "\n",
    "\n",
    "def claenagain(corpus):\n",
    "    for wordlist in corpus:\n",
    "        for word in wordlist:\n",
    "            word = ''.join(filter(str.isalpha, word))\n",
    "    return corpus\n",
    "\n",
    "\n",
    "x_train=claenagain(x_train) \n",
    "x_test=claenagain(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12080024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.04492188e-01 -3.12500000e-01  2.13867188e-01  3.08593750e-01\n",
      " -1.60156250e-01  9.42382812e-02 -1.60156250e-01 -3.22265625e-02\n",
      "  1.69921875e-01  8.49609375e-02 -1.38671875e-01 -2.31445312e-01\n",
      " -6.49414062e-02  6.68945312e-02 -2.16796875e-01  1.82617188e-01\n",
      " -2.17773438e-01 -8.78906250e-03 -7.32421875e-02 -2.44140625e-01\n",
      "  1.52343750e-01  1.20605469e-01  3.47656250e-01  7.42187500e-02\n",
      "  7.03125000e-02  2.05078125e-01 -1.24023438e-01  1.80664062e-01\n",
      "  1.02539062e-01 -1.17675781e-01  9.08203125e-02  9.71679688e-02\n",
      " -1.92871094e-02  1.95312500e-01 -1.08886719e-01  6.49414062e-02\n",
      "  3.32031250e-01 -7.37304688e-02 -1.27929688e-01  4.96093750e-01\n",
      "  1.16699219e-01 -6.54296875e-02  3.06640625e-01  1.28906250e-01\n",
      " -3.27148438e-02 -1.74804688e-01 -1.33789062e-01 -2.79296875e-01\n",
      " -1.66992188e-01  1.60156250e-01 -3.16406250e-01 -1.95312500e-02\n",
      "  1.73339844e-02  2.63671875e-01  9.76562500e-02 -1.37939453e-02\n",
      " -1.36718750e-01 -2.14843750e-01  2.07519531e-02 -1.17675781e-01\n",
      "  7.03125000e-02 -1.10351562e-01  3.39355469e-02 -6.03027344e-02\n",
      "  1.74560547e-02 -4.04296875e-01 -2.10937500e-01  1.75781250e-02\n",
      " -2.18750000e-01  1.01562500e-01  1.29882812e-01  1.99218750e-01\n",
      "  8.36181641e-03  1.27929688e-01 -4.51171875e-01 -1.89453125e-01\n",
      " -8.30078125e-02  2.05078125e-01 -8.36181641e-03  1.43554688e-01\n",
      " -2.85156250e-01  1.22070312e-01 -1.21582031e-01 -2.96875000e-01\n",
      " -3.14453125e-01  2.50000000e-01  1.26953125e-01  2.67578125e-01\n",
      "  3.41796875e-01 -1.34765625e-01 -1.27929688e-01  2.89062500e-01\n",
      " -1.28906250e-01 -1.73339844e-02 -1.04003906e-01  2.12402344e-02\n",
      "  2.27539062e-01 -3.19824219e-02 -1.29882812e-01 -9.66796875e-02\n",
      " -2.75390625e-01  6.68945312e-02 -6.49414062e-02 -1.46484375e-01\n",
      "  9.09423828e-03 -1.81640625e-01 -8.05664062e-02  1.18164062e-01\n",
      "  1.70898438e-02 -2.57568359e-02 -2.61718750e-01 -4.76562500e-01\n",
      "  6.93359375e-02 -6.98242188e-02  3.49121094e-02 -2.89916992e-03\n",
      "  6.00585938e-02  2.13623047e-02  1.99218750e-01 -8.78906250e-02\n",
      " -2.53906250e-01 -3.19824219e-02  4.99725342e-04  3.75976562e-02\n",
      "  1.82617188e-01 -1.61132812e-01 -6.48437500e-01 -7.08007812e-02\n",
      "  2.11181641e-02 -1.21582031e-01 -2.26562500e-01 -7.81250000e-03\n",
      "  2.40234375e-01  2.91015625e-01  1.98974609e-02  8.20312500e-02\n",
      " -7.27539062e-02  1.11328125e-01  1.14746094e-02 -2.38037109e-03\n",
      "  3.16406250e-01 -1.80664062e-01 -7.08007812e-02  1.05285645e-03\n",
      "  1.02233887e-03  2.37304688e-01  4.00390625e-02 -3.10546875e-01\n",
      "  2.50244141e-02 -1.58203125e-01  1.61132812e-01 -2.64892578e-02\n",
      "  1.37695312e-01 -2.15820312e-01 -6.93359375e-02  8.20312500e-02\n",
      " -1.47460938e-01 -1.02050781e-01 -1.47460938e-01 -1.19140625e-01\n",
      " -8.74023438e-02  1.00585938e-01 -2.46582031e-02  1.94335938e-01\n",
      " -5.54199219e-02 -4.10156250e-01 -5.37109375e-03 -1.63085938e-01\n",
      " -4.06250000e-01  2.06054688e-01 -2.90527344e-02  1.22680664e-02\n",
      "  4.23828125e-01  1.96289062e-01 -1.70898438e-01 -1.06201172e-02\n",
      "  2.50000000e-01 -1.87500000e-01  1.31835938e-02  1.76757812e-01\n",
      "  5.61523438e-02  5.27343750e-02  1.69921875e-01 -1.96289062e-01\n",
      "  6.16455078e-03  2.47070312e-01 -1.78222656e-02 -1.38671875e-01\n",
      "  1.45507812e-01  4.02832031e-02  2.57812500e-01  7.66601562e-02\n",
      "  1.69921875e-01  2.07031250e-01  2.03125000e-01  1.70898438e-01\n",
      " -9.52148438e-02 -1.10351562e-01  1.55639648e-02  1.54296875e-01\n",
      " -5.95703125e-02  2.69531250e-01 -9.08203125e-02 -8.15429688e-02\n",
      "  1.16577148e-02 -1.22070312e-01 -2.77343750e-01 -2.16064453e-02\n",
      " -2.45117188e-01  4.90722656e-02 -3.20434570e-03  2.09960938e-01\n",
      " -1.68945312e-01 -8.66699219e-03 -2.06054688e-01 -1.06445312e-01\n",
      "  2.39257812e-01  7.61718750e-02 -2.01171875e-01 -7.76367188e-02\n",
      " -3.32031250e-01  1.11328125e-01  1.23046875e-01  1.22680664e-02\n",
      "  4.27734375e-01 -8.83789062e-02 -5.10253906e-02 -2.17285156e-02\n",
      " -9.91210938e-02 -2.08984375e-01 -9.52148438e-02 -1.85546875e-01\n",
      " -2.27539062e-01 -4.46777344e-02  3.75000000e-01  1.38671875e-01\n",
      " -8.44726562e-02  1.90429688e-01  3.08593750e-01 -2.08740234e-02\n",
      "  2.28515625e-01 -7.03125000e-02 -1.30859375e-01 -2.17285156e-02\n",
      " -1.45507812e-01 -5.83496094e-02  5.32226562e-02  3.53515625e-01\n",
      "  4.00390625e-02 -2.58789062e-02  8.83789062e-02  2.14843750e-02\n",
      " -3.80859375e-02  3.37890625e-01  1.55273438e-01 -2.81250000e-01\n",
      " -1.65039062e-01  1.97753906e-02  2.08984375e-01 -1.62109375e-01\n",
      " -9.91210938e-02  3.50952148e-03 -5.37109375e-02 -1.87500000e-01\n",
      " -1.81640625e-01 -7.55310059e-04 -2.61718750e-01 -1.95312500e-01\n",
      " -7.12890625e-02 -1.08398438e-01 -3.41796875e-01  2.89062500e-01\n",
      "  4.16015625e-01  1.92382812e-01  1.55273438e-01 -4.78515625e-02\n",
      " -2.98828125e-01  1.16699219e-01 -2.04101562e-01  1.68945312e-01\n",
      "  6.20117188e-02 -7.51953125e-02  1.35742188e-01  2.46093750e-01\n",
      "  7.37304688e-02 -1.08032227e-02  2.10937500e-01 -1.44531250e-01\n",
      "  5.00488281e-02 -9.81445312e-02  1.70898438e-01  2.23632812e-01\n",
      " -4.08203125e-01  1.34765625e-01 -3.75000000e-01 -2.34375000e-01\n",
      " -1.07910156e-01 -9.61914062e-02 -1.57226562e-01  3.00292969e-02]\n"
     ]
    }
   ],
   "source": [
    "###编写代码，采用自训练或者预训练方式获得word2vec词向量\n",
    "\n",
    "from operator import mod\n",
    "from gensim.models import KeyedVectors    \n",
    "model=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors \n",
    "from gensim.test.utils import datapath, get_tmpfile   #word similarity package\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "eg = model['fuck']\n",
    "print(eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05da334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #编写函数并调用，通过对句子中的词向量求平均的方式获得句子的分布式表示，用于下文分类.\n",
    "# #获得的训练集的向量矩阵存入train_vecs, 测试集的向量矩阵存入test_vecs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wordlist2vecs(corpus):\n",
    "    res = []\n",
    "    for wordlist in corpus:\n",
    "        vecs = np.array([0]*300,dtype='float64')\n",
    "        count = 0\n",
    "        for word in wordlist:\n",
    "            try:\n",
    "                vecs += model[word]\n",
    "            except:\n",
    "                count += 1\n",
    "        div = np.array([len(wordlist)-count]*300,dtype='float64')\n",
    "        vecs = np.divide(vecs,div)\n",
    "        res.append(vecs)\n",
    "\n",
    "    return np.array(res)\n",
    "    \n",
    "\n",
    "train_vecs = wordlist2vecs(x_train)\n",
    "test_vecs = wordlist2vecs(x_test)\n",
    "# try:\n",
    "#     model.get_index('a')\n",
    "# except:\n",
    "#     print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48203426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       609\n",
      "           1       0.96      0.99      0.97       809\n",
      "\n",
      "    accuracy                           0.97      1418\n",
      "   macro avg       0.97      0.96      0.97      1418\n",
      "weighted avg       0.97      0.97      0.97      1418\n",
      "\n",
      "Acc: 0.97\n"
     ]
    }
   ],
   "source": [
    "#向量缩放\n",
    "from sklearn.preprocessing import scale\n",
    "train_vecs=scale(train_vecs)\n",
    "test_vecs=scale(test_vecs)\n",
    "\n",
    "#分类\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import  svm\n",
    "clf = svm.SVC(kernel='linear', gamma=10)\n",
    "clf.fit(train_vecs,y_train)\n",
    "y_pred=clf.predict(test_vecs)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('Acc: %.2f' % clf.score(test_vecs, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01654ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       609\n",
      "           1       0.95      0.94      0.95       809\n",
      "\n",
      "    accuracy                           0.94      1418\n",
      "   macro avg       0.94      0.94      0.94      1418\n",
      "weighted avg       0.94      0.94      0.94      1418\n",
      "\n",
      "Acc: 0.94\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#using SLG to train classifier model, and assess\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "lr=SGDClassifier(loss='log',penalty='l1')\n",
    "lr.fit(train_vecs,y_train)\n",
    "y_pred = lr.predict(test_vecs)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print('Acc: %.2f' % lr.score(test_vecs, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
